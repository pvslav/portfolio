{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef64c80d-f07e-4dff-8812-46cec4624059",
   "metadata": {},
   "source": [
    "# Pandas fundamentals\n",
    "\n",
    "Use `SHIFT+TAB` to see help on functions here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8edc067-8992-40e0-ac89-480df23bb9ef",
   "metadata": {},
   "source": [
    "## Filtering and ordering\n",
    "\n",
    "Filtering, or conditional selection, produces a Series of True/False booleans based on the specified condition of each record.\n",
    "\n",
    "Examples:\n",
    "\n",
    "`df[df['column_name'] <= 100]`\n",
    "\n",
    "`df.loc[df.column_name <= 100]`\n",
    "\n",
    "\n",
    "#### Combining conditions using AND / OR logic\n",
    "\n",
    "We can use the ampersand `(&)` to bring the two conditions together and apply `'AND'` logic, or use `(|)` to apply `'OR'` logic.\n",
    "\n",
    "Example:\n",
    "\n",
    "`df.loc[(df.year>2016) & (df.brand == 'Honda')]`\n",
    "\n",
    "`df.loc[(df.year>2016) | (df.brand == 'Honda')]`\n",
    "\n",
    "\n",
    "#### Using `isin` to check if the data is in the list of values\n",
    "\n",
    "We can use `isin`\n",
    "\n",
    "`df.loc[df.brand.isin(['Honda','Nissan','Toyota'])]`\n",
    "\n",
    "\n",
    "#### Using `isnull()` and `notnull()` to find empty and non-empty data\n",
    "\n",
    "`df.loc[df.price.isnull()]`\n",
    "\n",
    "`df.loc[df.price.notnull()]`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a676c9c9-6761-418d-be96-d6bcb2e887ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILTERING\n",
    "\n",
    "# Filter by column value\n",
    "df[df['column_name'] <= 100]\n",
    "\n",
    "# Filter by checking if column values are in the list\n",
    "specific_countries = ['Bangladesh', 'Brazil']\n",
    "df[df['Country'].isin(specific_countries)]\n",
    "\n",
    "# Filter by checking if column values contains string fragment\n",
    "df[df['Country'].str.contains('United')]\n",
    "\n",
    "# Set the DataFrame index using existing column\n",
    "df2 = df.set_index('Country')\n",
    "\n",
    "## Filtering by column names. axis = 1 - indicates we search in column names\n",
    "df2.filter(items=['Continent','CCA3'], axis = 1)\n",
    "\n",
    "## Filter by column names using 'like'\n",
    "df2.filter(like = 'Pop', axis = 1) # lists all columns which names contain 'Pop'\n",
    "\n",
    "## Filtering by row names (index). axis = 0 - indicates we search in row names\n",
    "df2.filter(items=['Zimbabwe'], axis = 0)\n",
    "\n",
    "## Filter by row names using 'like'\n",
    "df2.filter(like = 'United', axis = 0)\n",
    "\n",
    "## Filter by row name\n",
    "df2.loc['Zambia']\n",
    "\n",
    "## Filter by row position (integer)\n",
    "df2.iloc[51]\n",
    "\n",
    "\n",
    "# SORTING / ORDERING\n",
    "\n",
    "# Sorting by column descending\n",
    "df[df['Rank'] < 10].sort_values(by='Rank', ascending=False)\n",
    "\n",
    "# Sorting by a few columns ascending\n",
    "df[df['Rank'] < 10].sort_values(by=['Continent','Country'], ascending=True)\n",
    "\n",
    "# Sorting by a few columns applying different ascending option to each sorted column\n",
    "df[df['Rank'] < 10].sort_values(by=['Continent','Country'], ascending=[True,False])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c7a071-bf6b-4f9e-849e-417016e6ed66",
   "metadata": {},
   "source": [
    "## Indexing\n",
    "\n",
    "Index is an object that stores the access labels for all Pandas objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b862416c-3611-4c65-9b68-c0cfd3b4b4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifying custom index\n",
    "\n",
    "# Set the DataFrame index using existing column\n",
    "df = df.set_index('Country')\n",
    "\n",
    "## Set the DataFrame index using existing column without saving df to a variable using 'inplace = True'\n",
    "## if use w/o inplace=True, changes won't save\n",
    "df.set_index('Country', inplace = True)\n",
    "\n",
    "# Alternative way to set custom index while reading file\n",
    "df = pd.read_csv(\"world_population.csv\", index_col = \"Country\")\n",
    "\n",
    "# Importing dataset to pandas dataframe with Date column, making index to be the Date column, and parse each index value as Date\n",
    "pd.read_csv(\"path_to_dataset_file\", index_col=\"Date\", parse_dates=True)\n",
    "\n",
    "# Reset the index. inplace=True means modifying existing dataframe instead of creating a new one\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "# Setting multi-index. In the example below, two columns 'Continent' and 'Country' will be the index\n",
    "df.set_index(['Continent', 'Country'], inplace=True)\n",
    "\n",
    "# Sort index\n",
    "df.sort_index()\n",
    "df.sort_index(ascending=False) # in descending order\n",
    "df.sort_index(ascending=[False, True]) # specify different sorting order for different indexes\n",
    "\n",
    "# Accessing elements using loc and iloc in multi-indexed dataframe\n",
    "df.loc['Africa', 'Angola'] # searching for 'Africa' as a continent and 'Angola' as a country\n",
    "df.iloc[0] # even in case of multi-indexed dataframe will be lookup rows using initial integer-based index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98b8485-7a7f-4826-b702-f1cf1fceaeb9",
   "metadata": {},
   "source": [
    "## Indexing, Selecting & Assigning\n",
    "\n",
    "Two valid ways of accessing fields in Pandas dataframe:\n",
    " - `df.column_name`. For example, `pd.country`. It won't work if there spaces and other symbols in column name. In this regard, using [] approach is safer.\n",
    " - `df['column_name']`. For example, `pd['country']`\n",
    "\n",
    "Pandas Dataframe represents the whole dataset, whereas pandas Series represents a column of it.\n",
    "\n",
    "Indexing operator `[]` can be used to access single specific value of a column,\n",
    "for example \n",
    "`reviews['country'][0]`\n",
    "\n",
    "\n",
    "### Indexing in Pandas\n",
    "Using pandas accessor operators, `loc` and `iloc`.\n",
    "Both `loc` and `iloc` are row-first, column-second.\n",
    "\n",
    "`loc` and `iloc` use slightly different indexing schemes:\n",
    " - `iloc` - the first element of the range is included and the last one excluded. So `0:10` will select entries `0,...,9`\n",
    " - `loc` - the first element of the range is included and the last one is included. So `0:10` will select entries `0,...,10`\n",
    "\n",
    "Otherwise, the semantics of using `loc` are the same as those for `iloc`.\n",
    "\n",
    "Two paradigms for attribute selection:\n",
    " - index-based selection\n",
    " - label-based selection\n",
    "\n",
    "\n",
    "#### index-based selection\n",
    "Selecting data based on its numerical position in the data. `iloc` follows this paradigm.\n",
    "\n",
    "When we use `iloc` we treat the dataset like a big matrix (a list of lists), one that we have to index into by position.\n",
    "\n",
    "`df.iloc[row_index, column_index]` - general format\n",
    "\n",
    "`df.iloc[0]` - selects the first row of data in a DataFrame\n",
    "\n",
    "`df.iloc[:, 0]` - selects the first column of data in a DataFrame\n",
    "\n",
    "`df.iloc[:3, 0]` - selects the first three rows from the first column in a DataFrame\n",
    "\n",
    "`df.iloc[1:3, 2]` - selects the second and third entries from the third column in a DataFrame\n",
    "\n",
    "It's also possible to pass a list:\n",
    "`df.iloc[[1,2,3,5,8]]` - selects rows with indexes 1, 2, 3, 5, and 8 \n",
    "`df.iloc[[5, 7, 11], 4]` - selects the 6th, 8th, and 12th rows from the 5-th column in a DataFrame\n",
    "`df.loc[[0,1,10,100], ['country','province','region_1','region_2']]` - selects rows with indexes 0, 1, 10, 100 from columns 'country','province','region_1','region_2'.\n",
    "\n",
    "Negative numbers can be used in selection. \n",
    "This will start counting forwards from the end of the values. \n",
    "\n",
    "`df.iloc[-5:]` - selects the last five elements of the dataset\n",
    "`df.iloc[-5:, 4]` - selects the last five elements from the 5-th column of the dataset\n",
    "\n",
    "\n",
    "#### Label-based selection\n",
    "The second paradigm for attribute selection. It uses the `loc` operator. In this paradigm, it's the data index value, not its position. So, `loc` uses the information in the indices to do its work.\n",
    "\n",
    "`df.loc[0, 'column_name']` - get the first entry from the column in data frame\n",
    "\n",
    "`df.loc[:4, ['col_name1', 'col_name2', 'col_name3']]` - gets the first four rows for specified column names\n",
    "\n",
    "\n",
    "\n",
    "### Assigning data\n",
    "\n",
    "#### Assigning a constant value\n",
    "\n",
    "`df['column_name'] = 'value'`\n",
    "Each row in the column will have this value\n",
    "\n",
    "#### Assigning an iterable of values\n",
    "\n",
    "`df['index_backwards'] = range(len(df), 0, -1)`\n",
    "\n",
    "\n",
    "### Other\n",
    "\n",
    "`idxmax()` - method used to find the index label of the first occurrence of the maximum value in a pandas Series or DataFrame. It returns the index label of the row that contains the maximum value.\n",
    "\n",
    "`max_index = df['column_name'].idxmax()`\n",
    "\n",
    "`df.loc[max_index, 'another_column_name']`\n",
    "This combination can be used to solve such tasks as \"Find the attribute of the dataset with the highest another attribute in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efa5437-3422-4d1f-84c6-1b1b9844e2ca",
   "metadata": {},
   "source": [
    "## Summary Functions and Maps\n",
    "\n",
    "### Some summary functions\n",
    "\n",
    "`df.column_name.mean()` - calculates the mean for the column\n",
    "\n",
    "`df.column_name.median()` - calculates the median for the column\n",
    "\n",
    "`df.column_name.unique()` - shows a list of unique values in the column\n",
    "\n",
    "`df.column_name.nunique()` - shows the number of unique values in the column\n",
    "\n",
    "`df.column_name.value_counts()` - shows a list of unique values and how often they occur in the dataset\n",
    "\n",
    "\n",
    "### Maps\n",
    "\n",
    "Map is a function that takes one set of values and \"maps\" them to another set of values. \n",
    "\n",
    "There are two mapping methods:\n",
    " - `map()`\n",
    " - `apply()`\n",
    "\n",
    "`map()` and `apply()` return new, transformed Series and DataFrames, respectively. They don't modify the original data they're called on. \n",
    "\n",
    "#### Using `map()`\n",
    "For example, suppose that we wanted to remean the scores the wines received to 0. We can do this as follows:\n",
    "\n",
    "`review_points_mean = reviews.points.mean()`\n",
    "`reviews.points.map(lambda p: p - review_points_mean)`\n",
    "\n",
    "The function you pass to `map()` should expect a single value from the Series (a point value, in the above example), and return a transformed version of that value. \n",
    "`map()` returns a new Series where all the values have been transformed by your function.\n",
    "\n",
    "\n",
    "#### Using `apply()`\n",
    "`apply()` is the equivalent method if we want to transform a whole DataFrame by calling a custom method on each row.\n",
    "\n",
    "```\n",
    "def remean_points(row):\n",
    "    row.points = row.points - review_points_mean\n",
    "    return row\n",
    "\n",
    "reviews.apply(remean_points, axis='columns')\n",
    "```\n",
    "\n",
    "If we had called `reviews.apply()` with `axis='index'`, then instead of passing a function to transform each *row*, we would need to give a function to transform each *column*.\n",
    "\n",
    "\n",
    "#### Other\n",
    "Pandas provides many common mapping operations as built-ins. For example, here's a faster way of remeaning our points column:\n",
    "\n",
    "```\n",
    "review_points_mean = reviews.points.mean()\n",
    "reviews.points - review_points_mean\n",
    "```\n",
    "\n",
    "In this code we are performing an operation between a lot of values on the left-hand side (everything in the Series) and a single value on the right-hand side (the mean value).\n",
    "\n",
    "\n",
    "An easy way of combining `country` and `region` information in the dataset would be to do the following:\n",
    "\n",
    "`reviews.country + \" - \" + reviews.region_1`\n",
    "\n",
    "`df.brand + ' ' + df.model_name`\n",
    "\n",
    "`df.price * 2`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e91f6a-0048-42c1-844f-35151cf680e8",
   "metadata": {},
   "source": [
    "## Group by and Aggregating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2eba372-a5f4-463c-a837-6da82e09c23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'Base Flavor' field and calculate 'mean' for all integer fields in the dataframe\n",
    "df.groupby('Base Flavor').mean()\n",
    "\n",
    "# size() vs count()\n",
    "## size() method calculates the total number of records within each group, including both non-null and null values, \n",
    "## count() method calculates the number of non-null values within each group.\n",
    "### Group by 'Base Flavor' field and calculate 'count' for all fields in the dataframe\n",
    "df.groupby('Base Flavor').count()\n",
    "### Group by column_name and calculate the number of entries in each group\n",
    "df.groupby('column_name').size()\n",
    "\n",
    "# Group by column_name, calcuate count for each group and sort values in descending order\n",
    "df.groupby('column_name').size().sort_values(ascending=False)\n",
    "\n",
    "# Group by 'Base Flavor' field and calculate 'min' for all fields in the dataframe.\n",
    "## for string values it shows first value in the alphabetical order\n",
    "df.groupby('Base Flavor').min()\n",
    "\n",
    "# Group by 'Base Flavor' field and calculate 'max' for all fields in the dataframe.\n",
    "## for string values it shows last value in the alphabetical order\n",
    "df.groupby('Base Flavor').max()\n",
    "\n",
    "# Group by 'Base Flavor' field and calculate 'sum' for all integer fields in the dataframe\n",
    "df.groupby('Base Flavor').sum()\n",
    "\n",
    "# Group by 'Base Flavor' field and calculate 'mean' for the 'Flavor Rating' field\n",
    "df.groupby('Base Flavor')['Flavor Rating'].mean()\n",
    "\n",
    "# Using `agg()` method - allows to run a bunch of different functions on DataFrame simultaneously\n",
    "## for example, generate a simple statistical summary of the dataset as follows:\n",
    "df.groupby(['column_name']).column_name.agg([len, min, max])\n",
    "\n",
    "# General syntax of grouping and aggregating\n",
    "df.groupby('column_name').agg({'column_name': 'aggregation_function_name'})\n",
    "## for example.\n",
    "df.groupby('Base Flavor').agg({'Total Rating': 'max'})\n",
    "\n",
    "## Making several aggregation functions at once \n",
    "df.groupby('Base Flavor').agg({'Total Rating': ['mean','max','count','sum']})\n",
    "\n",
    "## Making several aggregation functions for several fields at once \n",
    "df.groupby('Base Flavor').agg({'Total Rating': ['mean','max','count','sum'], 'Flavor Rating': ['mean','max','count','sum']})\n",
    "\n",
    "## Grouping by several fields and making several aggregation functions for several fields at once\n",
    "df.groupby(['Base Flavor','Liked']).agg({'Total Rating': ['mean','max','count','sum'], 'Flavor Rating': ['mean','max','count','sum']})\n",
    "\n",
    "## Using describe() function to show general statistics for the grouped dataframe\n",
    "df.groupby(['Base Flavor']).describe()\n",
    "\n",
    "## Example: selecting the name of the first wine reviewed from each winery in the vines dataset\n",
    "df.groupby('winery').apply(lambda x: x.title.iloc[0])\n",
    "\n",
    "## Example: pick out the wine with max score by country and province\n",
    "df.groupby(['country', 'province']).apply(lambda x: x.loc[x.points.idxmax()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2751033a-586c-4c09-8def-38b1ccb56b53",
   "metadata": {},
   "source": [
    "## Renaming\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6f5083-4373-4ae4-83c8-9400344aa828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename dataframe column name\n",
    "df.rename(columns={'old_column_name': 'new_column_name'})\n",
    "\n",
    "# Rename two columns in dataframe at once\n",
    "df.rename(columns={'old_column1_name': 'new_column1_name', 'old_column2_name': 'new_column2_name'})\n",
    "df.rename(columns=dict(old_column1_name='new_column1_name', old_column2_name='new_column2_name')) \n",
    "\n",
    "# Rename first two entries of index\n",
    "df.rename(index={0: 'firstEntry', 1: 'secondEntry'})\n",
    "\n",
    "# Rename the name attribute for row index and the column index \n",
    "df.rename_axis(\"wines\", axis='rows').rename_axis(\"fields\", axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6539add8-c360-4051-a750-cad6b2fce4f8",
   "metadata": {},
   "source": [
    "## Merge, Join, and Concatenate dataframes in Pandas\n",
    "\n",
    "![image.png](./image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ddbd90-d54e-43b8-869c-6764a44a99f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MERGE #\n",
    "\n",
    "## The default join type in merge() is an inner join, which keeps only the rows with matching keys in both DataFrames.\n",
    "\n",
    "# Merging two dataframes, df1 and df2, using inner join and one common field 'FellowshipID'\n",
    "df1.merge(df2, how = 'inner', on = 'FellowshipID')\n",
    "\n",
    "# Merging two dataframes, df1 and df2, using inner join and two common fields, 'FellowshipID' and 'FirstName'\n",
    "df1.merge(df2, how = 'inner', on = ['FellowshipID', 'FirstName'])\n",
    "## the same result can be achieved by using `df1.merge(df2)` command. It's possible due to default values in the function\n",
    "\n",
    "# Merging two dataframes, df1 and df2, using inner join and columns from both dataframes\n",
    "df1.merge(df2, how='inner', left_on='df1_column', right_on='df2_column')\n",
    "\n",
    "# Merging two dataframes, df1 and df2, using outer join\n",
    "df1.merge(df2, how = 'outer')\n",
    "\n",
    "# Merging two dataframes, df1 and df2, using left join\n",
    "df1.merge(df2, how = 'left')\n",
    "\n",
    "# Merging two dataframes, df1 and df2, using right join\n",
    "df1.merge(df2, how = 'right')\n",
    "\n",
    "# Merging two dataframes, df1 and df2, using cross join that returns the Cartesian product of rows from the tables in the join. \n",
    "# In other words, it combines each row from the first table with each row from the second table\n",
    "df1.merge(df2, how = 'cross')\n",
    "\n",
    "\n",
    "# JOIN #\n",
    "## join() lets combine different DataFrame objects which have an index in common\n",
    "\n",
    "## The default join type in join() is a left join.\n",
    "## Functions the same as 'merge', but has a bit trickier syntax. So, it might be easier to use 'merge' for joins.\n",
    "\n",
    "# Joining two dataframes, df1 and df2. 'how' specifies type of join, 'inner', 'outer', 'left', 'right', 'cross'\n",
    "df3 = df1.set_index('FellowshipID').join(df2.set_index('FellowshipID'), lsuffix = '_Left', rsuffix = '_Right', how = 'inner')\n",
    "\n",
    "\n",
    "# CONCATENATE #\n",
    "\n",
    "## As opposed to 'join' and 'merge', 'concat' combines one dataframe on top of another, functioning similar to\n",
    "## 'UNION ALL' in SQL\n",
    "\n",
    "# Combining two dataframes, df1 and df2.\n",
    "pd.concat([df1, df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5812a7c-3fef-43d4-8c6f-5fd2466e58c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
